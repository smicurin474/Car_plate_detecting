{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":558039,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":424027,"modelId":441537}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Установка необходимых зависимостей\n!pip install ultralytics\n!pip install torch torchvision\n!pip install albumentations\n\n# Настройка CUDA для лучшего управления памятью\nimport os\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\n# Клонирование репозитория с обученной моделью\n!git clone https://github.com/smicurin474/Car_plate_detecting.git\n\n# Добавляем путь к репозиторию в PYTHONPATH\nimport sys\nsys.path.append('/kaggle/working/Car_plate_detecting')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-03T15:51:03.438153Z","iopub.execute_input":"2025-09-03T15:51:03.438886Z","iopub.status.idle":"2025-09-03T15:52:21.913904Z","shell.execute_reply.started":"2025-09-03T15:51:03.438850Z","shell.execute_reply":"2025-09-03T15:52:21.913114Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.192-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.4)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\nRequirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\nRequirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.21.0)\nCollecting ultralytics-thop>=2.0.0 (from ultralytics)\n  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.192-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.192 ultralytics-thop-2.0.17\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.8)\nRequirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.26.4)\nRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.15.3)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations) (6.0.2)\nRequirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.11.7)\nRequirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.11/dist-packages (from albumentations) (0.0.24)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations) (4.11.0.86)\nRequirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (3.12.5)\nRequirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.24->albumentations) (6.4.9)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.24.4->albumentations) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.33.2)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (4.14.0)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.24.4->albumentations) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.24.4->albumentations) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.24.4->albumentations) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.24.4->albumentations) (2024.2.0)\nCloning into 'Car_plate_detecting'...\nremote: Enumerating objects: 104, done.\u001b[K\nremote: Counting objects: 100% (104/104), done.\u001b[K\nremote: Compressing objects: 100% (95/95), done.\u001b[K\nremote: Total 104 (delta 3), reused 101 (delta 3), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (104/104), 13.70 MiB | 38.43 MiB/s, done.\nResolving deltas: 100% (3/3), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Загрузка датасета\n!mkdir -p /kaggle/working/finetune_dataset\n!wget https://huggingface.co/datasets/AY000554/Car_plate_detecting_dataset/resolve/main/train.zip\n!wget https://huggingface.co/datasets/AY000554/Car_plate_detecting_dataset/resolve/main/val.zip\n\n# Распаковка датасета\n!unzip -q train.zip -d /kaggle/working/finetune_dataset\n!unzip -q val.zip -d /kaggle/working/finetune_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T15:52:21.915318Z","iopub.execute_input":"2025-09-03T15:52:21.915561Z","iopub.status.idle":"2025-09-03T15:54:16.129190Z","shell.execute_reply.started":"2025-09-03T15:52:21.915536Z","shell.execute_reply":"2025-09-03T15:54:16.128165Z"}},"outputs":[{"name":"stdout","text":"--2025-09-03 15:52:22--  https://huggingface.co/datasets/AY000554/Car_plate_detecting_dataset/resolve/main/train.zip\nResolving huggingface.co (huggingface.co)... 18.244.202.68, 18.244.202.60, 18.244.202.73, ...\nConnecting to huggingface.co (huggingface.co)|18.244.202.68|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://cdn-lfs-us-1.hf.co/repos/f5/fb/f5fb9d95f122eb06ad36fa568b80b423cda743737da1285f498b17999aee4770/689e09a59fd1ba57584e45896ae9d87a205a201080d23116362d41c5e1b805c3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27train.zip%3B+filename%3D%22train.zip%22%3B&response-content-type=application%2Fzip&Expires=1756918342&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NjkxODM0Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2Y1L2ZiL2Y1ZmI5ZDk1ZjEyMmViMDZhZDM2ZmE1NjhiODBiNDIzY2RhNzQzNzM3ZGExMjg1ZjQ5OGIxNzk5OWFlZTQ3NzAvNjg5ZTA5YTU5ZmQxYmE1NzU4NGU0NTg5NmFlOWQ4N2EyMDVhMjAxMDgwZDIzMTE2MzYyZDQxYzVlMWI4MDVjMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=qGs4ZVRQvEoRRJFyk-H3rVTZ35Pvg4JNOBRIm61dTJ%7EiEQUqvqtU0VlbqVD0S75TYAd3VXFzo4fruA4Oas82keSUP1bKc4ZHkFxyR3ObyrMNrawBRQ9TpaYiceLx4XcEkUVdmfiCgu%7ExlGZ-sAid-r2clqUxIbZbkjK0Y%7EO2lZ0KnpsJetoYY0MAmD9DrhQPPkkyxJhsghOAZe6mvNojvwhYTQiMLc-HKwICS2xUfhOMnf-lPMSpOhgKPGcV6NY0BJ%7EkjpDHKW-nEDWQO2AFRUFpBOJ0FO%7EsNdKckJ3nTpnUumLhqMoECNvo3P6coLTeuvb6EAnQXto0gSmF1sqOSA__&Key-Pair-Id=K24J24Z295AEI9 [following]\n--2025-09-03 15:52:22--  https://cdn-lfs-us-1.hf.co/repos/f5/fb/f5fb9d95f122eb06ad36fa568b80b423cda743737da1285f498b17999aee4770/689e09a59fd1ba57584e45896ae9d87a205a201080d23116362d41c5e1b805c3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27train.zip%3B+filename%3D%22train.zip%22%3B&response-content-type=application%2Fzip&Expires=1756918342&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NjkxODM0Mn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2Y1L2ZiL2Y1ZmI5ZDk1ZjEyMmViMDZhZDM2ZmE1NjhiODBiNDIzY2RhNzQzNzM3ZGExMjg1ZjQ5OGIxNzk5OWFlZTQ3NzAvNjg5ZTA5YTU5ZmQxYmE1NzU4NGU0NTg5NmFlOWQ4N2EyMDVhMjAxMDgwZDIzMTE2MzYyZDQxYzVlMWI4MDVjMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=qGs4ZVRQvEoRRJFyk-H3rVTZ35Pvg4JNOBRIm61dTJ%7EiEQUqvqtU0VlbqVD0S75TYAd3VXFzo4fruA4Oas82keSUP1bKc4ZHkFxyR3ObyrMNrawBRQ9TpaYiceLx4XcEkUVdmfiCgu%7ExlGZ-sAid-r2clqUxIbZbkjK0Y%7EO2lZ0KnpsJetoYY0MAmD9DrhQPPkkyxJhsghOAZe6mvNojvwhYTQiMLc-HKwICS2xUfhOMnf-lPMSpOhgKPGcV6NY0BJ%7EkjpDHKW-nEDWQO2AFRUFpBOJ0FO%7EsNdKckJ3nTpnUumLhqMoECNvo3P6coLTeuvb6EAnQXto0gSmF1sqOSA__&Key-Pair-Id=K24J24Z295AEI9\nResolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.155.1.85, 18.155.1.112, 18.155.1.69, ...\nConnecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.155.1.85|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4459197400 (4.2G) [application/zip]\nSaving to: ‘train.zip’\n\ntrain.zip           100%[===================>]   4.15G  74.4MB/s    in 70s     \n\n2025-09-03 15:53:32 (60.7 MB/s) - ‘train.zip’ saved [4459197400/4459197400]\n\n--2025-09-03 15:53:32--  https://huggingface.co/datasets/AY000554/Car_plate_detecting_dataset/resolve/main/val.zip\nResolving huggingface.co (huggingface.co)... 18.244.202.118, 18.244.202.68, 18.244.202.73, ...\nConnecting to huggingface.co (huggingface.co)|18.244.202.118|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://cdn-lfs-us-1.hf.co/repos/f5/fb/f5fb9d95f122eb06ad36fa568b80b423cda743737da1285f498b17999aee4770/9c1773b64ddce658c9dfc568c3585a434ca747819caa0bb1195a1f6377a2227b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27val.zip%3B+filename%3D%22val.zip%22%3B&response-content-type=application%2Fzip&Expires=1756918412&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NjkxODQxMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2Y1L2ZiL2Y1ZmI5ZDk1ZjEyMmViMDZhZDM2ZmE1NjhiODBiNDIzY2RhNzQzNzM3ZGExMjg1ZjQ5OGIxNzk5OWFlZTQ3NzAvOWMxNzczYjY0ZGRjZTY1OGM5ZGZjNTY4YzM1ODVhNDM0Y2E3NDc4MTljYWEwYmIxMTk1YTFmNjM3N2EyMjI3Yj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=bDE2aqxNvejQIEv-rfXSmkJlAsTljMKNN-OvzRpK6fwqjQWno86jff7%7E3kPTurbnFFhoyJGdwU%7Ee5qgAy26zM-GfJVvIzXpG5BRglvbI6b7WkQpfL%7E7lP%7E5uFcCQiIRri2uQ5pzbx9L4ZXd9Pzd6eNFWtpTHl3SQi%7EMyTFjvxKlxz4xAOMynbcnQj9zElXr7Rhxh1zyW53DtvE3IWIz4iIpfnm2ydPegQ4aBcdGSR6OzI8iErvW%7EEv3IqSalsQs0GapKACZXun322IMkV850V2EOz39meLzDgyRt909Qk0QxTy8mmdMXLYuHgzIaCr3AeuRzbEdRLIlEDubf4tRR0w__&Key-Pair-Id=K24J24Z295AEI9 [following]\n--2025-09-03 15:53:32--  https://cdn-lfs-us-1.hf.co/repos/f5/fb/f5fb9d95f122eb06ad36fa568b80b423cda743737da1285f498b17999aee4770/9c1773b64ddce658c9dfc568c3585a434ca747819caa0bb1195a1f6377a2227b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27val.zip%3B+filename%3D%22val.zip%22%3B&response-content-type=application%2Fzip&Expires=1756918412&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1NjkxODQxMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2Y1L2ZiL2Y1ZmI5ZDk1ZjEyMmViMDZhZDM2ZmE1NjhiODBiNDIzY2RhNzQzNzM3ZGExMjg1ZjQ5OGIxNzk5OWFlZTQ3NzAvOWMxNzczYjY0ZGRjZTY1OGM5ZGZjNTY4YzM1ODVhNDM0Y2E3NDc4MTljYWEwYmIxMTk1YTFmNjM3N2EyMjI3Yj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=bDE2aqxNvejQIEv-rfXSmkJlAsTljMKNN-OvzRpK6fwqjQWno86jff7%7E3kPTurbnFFhoyJGdwU%7Ee5qgAy26zM-GfJVvIzXpG5BRglvbI6b7WkQpfL%7E7lP%7E5uFcCQiIRri2uQ5pzbx9L4ZXd9Pzd6eNFWtpTHl3SQi%7EMyTFjvxKlxz4xAOMynbcnQj9zElXr7Rhxh1zyW53DtvE3IWIz4iIpfnm2ydPegQ4aBcdGSR6OzI8iErvW%7EEv3IqSalsQs0GapKACZXun322IMkV850V2EOz39meLzDgyRt909Qk0QxTy8mmdMXLYuHgzIaCr3AeuRzbEdRLIlEDubf4tRR0w__&Key-Pair-Id=K24J24Z295AEI9\nResolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 13.32.179.111, 13.32.179.118, 13.32.179.45, ...\nConnecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|13.32.179.111|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 548973290 (524M) [application/zip]\nSaving to: ‘val.zip’\n\nval.zip             100%[===================>] 523.54M   181MB/s    in 2.9s    \n\n2025-09-03 15:53:35 (181 MB/s) - ‘val.zip’ saved [548973290/548973290]\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Создаем отдельную директорию для тестирования аугментаций на сложных случаях\n!mkdir -p /kaggle/working/hard_cases_test/images\n!cp -r /kaggle/working/Car_plate_detecting/hard_cases/* /kaggle/working/hard_cases_test/images/\n\nprint(\"Количество изображений для дообучения:\", len(os.listdir('/kaggle/working/finetune_dataset/train/images')))\nprint(\"Количество изображений для валидации:\", len(os.listdir('/kaggle/working/finetune_dataset/val/images')))\nprint(\"Количество сложных случаев для тестирования:\", len(os.listdir('/kaggle/working/hard_cases_test/images')))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T15:59:10.282267Z","iopub.execute_input":"2025-09-03T15:59:10.282507Z","iopub.status.idle":"2025-09-03T15:59:10.544726Z","shell.execute_reply.started":"2025-09-03T15:59:10.282482Z","shell.execute_reply":"2025-09-03T15:59:10.543988Z"}},"outputs":[{"name":"stdout","text":"Количество изображений для дообучения: 20505\nКоличество изображений для валидации: 2563\nКоличество сложных случаев для тестирования: 37\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Функции для анализа сложных случаев\nfrom pathlib import Path\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport yaml\nfrom scipy.stats import entropy\nfrom skimage.filters import threshold_otsu\nfrom skimage.feature import local_binary_pattern\n\ndef compute_image_quality_metrics(image):\n    \"\"\"Расчет метрик качества изображения\"\"\"\n    if len(image.shape) == 3:\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    else:\n        gray = image\n        \n    # Метрики резкости\n    laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()\n    gradients = np.gradient(gray.astype(float))\n    gradient_magnitude = np.sqrt(gradients[0]**2 + gradients[1]**2)\n    gradient_mean = np.mean(gradient_magnitude)\n    \n    # Метрики контраста\n    contrast = gray.std()\n    local_contrast = np.mean([np.std(gray[i:i+16, j:j+16]) \n                            for i in range(0, gray.shape[0]-15, 16)\n                            for j in range(0, gray.shape[1]-15, 16)])\n    \n    # Гистограммные характеристики\n    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n    hist_norm = hist.ravel() / hist.sum()\n    hist_entropy = entropy(hist_norm)\n    \n    # Текстурные характеристики\n    lbp = local_binary_pattern(gray, 8, 1, method='uniform')\n    lbp_hist = np.histogram(lbp, bins=np.arange(0, 11))[0]\n    lbp_hist = lbp_hist.astype(float) / lbp_hist.sum()\n    texture_entropy = entropy(lbp_hist)\n    \n    return {\n        'sharpness': {\n            'laplacian_var': laplacian_var,\n            'gradient_mean': gradient_mean\n        },\n        'contrast': {\n            'global': contrast,\n            'local': local_contrast\n        },\n        'histogram': {\n            'entropy': hist_entropy,\n            'mean': np.mean(gray),\n            'std': np.std(gray)\n        },\n        'texture': {\n            'entropy': texture_entropy\n        }\n    }\n\ndef analyze_hard_cases(hard_cases_dir):\n    hard_cases_dir = Path(hard_cases_dir)\n    hard_cases = list(hard_cases_dir.glob('*.jpg'))\n    \n    problems = {\n        'blur': [],      # Размытые изображения\n        'dark': [],      # Темные изображения\n        'bright': [],    # Засвеченные изображения\n        'dirty': [],     # Грязные/стертые номера\n        'angle': [],     # Сильный угол наклона\n        'shadow': [],    # Тени на номере\n        'partial': []    # Частично закрытые номера\n    }\n    \n    # Сбор статистики по всем изображениям для нормализации\n    all_metrics = []\n    for img_path in hard_cases:\n        img = cv2.imread(str(img_path))\n        metrics = compute_image_quality_metrics(img)\n        all_metrics.append(metrics)\n    \n    # Расчет пороговых значений\n    thresholds = {\n        'sharpness': {\n            'laplacian_var': np.percentile([m['sharpness']['laplacian_var'] for m in all_metrics], 25),\n            'gradient_mean': np.percentile([m['sharpness']['gradient_mean'] for m in all_metrics], 25)\n        },\n        'contrast': {\n            'global': np.percentile([m['contrast']['global'] for m in all_metrics], 25),\n            'local': np.percentile([m['contrast']['local'] for m in all_metrics], 25)\n        },\n        'brightness': {\n            'low': np.percentile([m['histogram']['mean'] for m in all_metrics], 25),\n            'high': np.percentile([m['histogram']['mean'] for m in all_metrics], 75)\n        }\n    }\n    \n    for img_path in hard_cases:\n        img = cv2.imread(str(img_path))\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n        metrics = compute_image_quality_metrics(img)\n        \n        # 1. Анализ размытия (комплексный подход)\n        is_blurry = (\n            metrics['sharpness']['laplacian_var'] < thresholds['sharpness']['laplacian_var'] or\n            metrics['sharpness']['gradient_mean'] < thresholds['sharpness']['gradient_mean']\n        )\n        if is_blurry:\n            problems['blur'].append(img_path.name)\n        \n        # 2. Анализ грязи и стертости (улучшенный)\n        local_entropy = metrics['texture']['entropy']\n        local_contrast = metrics['contrast']['local']\n        if local_entropy < np.mean([m['texture']['entropy'] for m in all_metrics]) * 0.7 or \\\n           local_contrast < thresholds['contrast']['local']:\n            problems['dirty'].append(img_path.name)\n        \n        # 3. Анализ теней (улучшенный)\n        v_channel = hsv[:, :, 2]\n        thresh = threshold_otsu(v_channel)\n        binary = v_channel < thresh\n        shadow_ratio = np.sum(binary) / binary.size\n        if shadow_ratio > 0.3:  # Более 30% темных областей\n            problems['shadow'].append(img_path.name)\n        \n        # 4. Анализ яркого света/вспышек (улучшенный)\n        if metrics['histogram']['mean'] > thresholds['brightness']['high']:\n            v_channel_hist = np.histogram(v_channel, bins=256, range=(0, 256))[0]\n            bright_ratio = np.sum(v_channel_hist[200:]) / np.sum(v_channel_hist)\n            if bright_ratio > 0.1:  # Более 10% очень ярких пикселей\n                problems['bright'].append(img_path.name)\n        \n        # 5. Анализ углов (улучшенный)\n        # Используем комбинацию методов Хафа и градиентов\n        edges = cv2.Canny(gray, 50, 150)\n        lines = cv2.HoughLinesP(edges, 1, np.pi/180, 50, minLineLength=100, maxLineGap=10)\n        \n        if lines is not None:\n            angles = []\n            for line in lines:\n                x1, y1, x2, y2 = line[0]\n                angle = np.abs(np.degrees(np.arctan2(y2-y1, x2-x1)))\n                angles.append(angle)\n            \n            # Анализируем распределение углов\n            angle_hist = np.histogram(angles, bins=18, range=(0, 180))[0]\n            angle_entropy = entropy(angle_hist / angle_hist.sum())\n            if angle_entropy > 2.5 or np.std(angles) > 30:  # Высокая энтропия углов или большой разброс\n                problems['angle'].append(img_path.name)\n        \n        # 6. Анализ частично закрытых номеров (улучшенный)\n        # Используем анализ связных компонент и градиентов\n        gradients = np.hypot(cv2.Sobel(gray, cv2.CV_64F, 1, 0), \n                           cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n        \n        # Анализ распределения градиентов по областям\n        h_blocks = np.array_split(gradients, 3, axis=1)\n        v_blocks = np.array_split(gradients, 3, axis=0)\n        \n        h_means = [np.mean(block) for block in h_blocks]\n        v_means = [np.mean(block) for block in v_blocks]\n        \n        # Проверяем неравномерность распределения градиентов\n        h_variance = np.std(h_means) / np.mean(h_means)\n        v_variance = np.std(v_means) / np.mean(v_means)\n        \n        if h_variance > 0.5 or v_variance > 0.5:  # Значительная неравномерность\n            problems['partial'].append(img_path.name)\n    \n    # Анализ распределения проблем\n    total_images = len(hard_cases)\n    print(\"\\nСтатистика распределения проблем:\")\n    print(\"-\" * 50)\n    for problem_type, images in problems.items():\n        count = len(images)\n        percentage = (count / total_images) * 100\n        print(f\"{problem_type}: {count} изображений ({percentage:.1f}%)\")\n    \n    # Визуализация распределения проблем\n    plt.figure(figsize=(12, 6))\n    problem_counts = [len(cases) for cases in problems.values()]\n    plt.bar(problems.keys(), problem_counts)\n    plt.title('Распределение проблем в датасете')\n    plt.xticks(rotation=45)\n    plt.ylabel('Количество изображений')\n    plt.tight_layout()\n    plt.savefig('problem_distribution.png')\n    plt.close()\n    \n    return problems\n\n# Анализируем сложные случаи\nproblems = analyze_hard_cases('/kaggle/working/hard_cases_test/images')\n\n# Подробный вывод результатов\nprint(\"\\nАнализ сложных случаев:\")\nprint(\"-\" * 50)\nfor problem, cases in problems.items():\n    print(f\"\\n{problem.upper()}: {len(cases)} случаев\")\n    if cases:\n        print(\"Примеры:\")\n        for case in cases[:3]:\n            print(f\"  - {case}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T16:54:18.613882Z","iopub.execute_input":"2025-09-03T16:54:18.614185Z","iopub.status.idle":"2025-09-03T16:54:41.876831Z","shell.execute_reply.started":"2025-09-03T16:54:18.614159Z","shell.execute_reply":"2025-09-03T16:54:41.876058Z"}},"outputs":[{"name":"stdout","text":"\nСтатистика распределения проблем:\n--------------------------------------------------\nblur: 10 изображений (27.0%)\ndark: 0 изображений (0.0%)\nbright: 7 изображений (18.9%)\ndirty: 9 изображений (24.3%)\nangle: 6 изображений (16.2%)\nshadow: 31 изображений (83.8%)\npartial: 2 изображений (5.4%)\n\nАнализ сложных случаев:\n--------------------------------------------------\n\nBLUR: 10 случаев\nПримеры:\n  - 1403707_af61f7dc10024f6cdc213d517f2f8940_photo.jpg\n  - 1407817_4b6111bb4c6a7b488d1fbaae0b914661_photo.jpg\n  - 1051833_fdc4fc24282f6b4052aac00a3ca0000f_photo.jpg\n\nDARK: 0 случаев\n\nBRIGHT: 7 случаев\nПримеры:\n  - 1049142_1a9445ffd3c4a2efac5bf0cf67cdf732_photo.jpg\n  - 1407817_4b6111bb4c6a7b488d1fbaae0b914661_photo.jpg\n  - 1400932_05d2e84faf6c4a0ac1b13bcfe963314d_photo.jpg\n\nDIRTY: 9 случаев\nПримеры:\n  - 1407817_4b6111bb4c6a7b488d1fbaae0b914661_photo.jpg\n  - 1051833_fdc4fc24282f6b4052aac00a3ca0000f_photo.jpg\n  - 1399702_0f452608229dfa104d9473c520881a66_photo.jpg\n\nANGLE: 6 случаев\nПримеры:\n  - 1399702_0f452608229dfa104d9473c520881a66_photo.jpg\n  - 1403602_0743139ebb3c4151fa304129764f0051_photo.jpg\n  - 1400431_d252aed2a4d2a5e268ab8cefbb68a25b_photo.jpg\n\nSHADOW: 31 случаев\nПримеры:\n  - 1049142_1a9445ffd3c4a2efac5bf0cf67cdf732_photo.jpg\n  - 1407817_4b6111bb4c6a7b488d1fbaae0b914661_photo.jpg\n  - 1400932_05d2e84faf6c4a0ac1b13bcfe963314d_photo.jpg\n\nPARTIAL: 2 случаев\nПримеры:\n  - полуприцеп сложный13.jpg\n  - полцприцеп90.jpg\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"def validate_on_hard_cases(model, hard_cases_dir, epoch, problems):\n    hard_cases_dir = Path(hard_cases_dir)\n    hard_cases = list(hard_cases_dir.glob('*.jpg'))\n    \n    print(f\"\\nПроверка на сложных случаях (эпоха {epoch}):\")\n    \n    save_dir = Path(f'runs/detect/hard_cases_epoch_{epoch}')\n    save_dir.mkdir(parents=True, exist_ok=True)\n    \n    problem_stats = {\n        'blur': {'total': len(problems['blur']), 'detected': 0},\n        'dark': {'total': len(problems['dark']), 'detected': 0},\n        'bright': {'total': len(problems['bright']), 'detected': 0},\n        'dirty': {'total': len(problems['dirty']), 'detected': 0},\n        'angle': {'total': len(problems['angle']), 'detected': 0},\n        'shadow': {'total': len(problems['shadow']), 'detected': 0},\n        'partial': {'total': len(problems.get('partial', [])), 'detected': 0}\n    }\n    \n    for img_path in hard_cases:\n        results = model.predict(str(img_path), save=False, verbose=False)[0]\n        \n        for problem_type, cases in problems.items():\n            if img_path.name in cases:\n                if len(results.boxes) > 0:\n                    problem_stats[problem_type]['detected'] += 1\n    \n    print(\"\\nРезультаты по типам проблем:\")\n    problem_detection_rates = {}\n    for problem_type, stats in problem_stats.items():\n        if stats['total'] > 0:\n            detection_rate = (stats['detected'] / stats['total']) * 100\n            problem_detection_rates[problem_type] = detection_rate\n            print(f\"{problem_type}: {stats['detected']}/{stats['total']} ({detection_rate:.1f}%)\")\n    \n    return problem_detection_rates\n\ndef get_augmentation_config(problem_type, severity=1.0):\n    \"\"\"\n    Возвращает конфигурацию аугментаций для конкретного типа проблемы\n    severity: уровень интенсивности аугментаций (0.0 - 1.0)\n    \"\"\"\n    import albumentations as A\n    \n    base_config = {\n        'blur': A.Compose([\n            A.OneOf([\n                A.MotionBlur(blur_limit=7),\n                A.GaussianBlur(blur_limit=7),\n                A.MedianBlur(blur_limit=7),\n            ], p=0.5 * severity),\n            A.ImageCompression(quality_lower=60, quality_upper=100, p=0.3 * severity),\n        ]),\n        \n        'dark': A.Compose([\n            A.RandomBrightnessContrast(\n                brightness_limit=(-0.3 * severity, 0.1),\n                contrast_limit=(-0.2 * severity, 0.2),\n                p=0.7 * severity\n            ),\n            A.HueSaturationValue(\n                hue_shift_limit=5,\n                sat_shift_limit=20,\n                val_shift_limit=(-30 * severity, 10),\n                p=0.5 * severity\n            ),\n        ]),\n        \n        'bright': A.Compose([\n            A.RandomBrightnessContrast(\n                brightness_limit=(0, 0.3 * severity),\n                contrast_limit=(-0.2 * severity, 0.2),\n                p=0.7 * severity\n            ),\n            A.HueSaturationValue(\n                hue_shift_limit=5,\n                sat_shift_limit=20,\n                val_shift_limit=(10, 30 * severity),\n                p=0.5 * severity\n            ),\n        ]),\n        \n        'dirty': A.Compose([\n            A.CoarseDropout(\n                max_holes=int(8 * severity),\n                max_height=3,\n                max_width=int(10 * severity),\n                min_holes=1,\n                p=0.5 * severity\n            ),\n            A.GridDistortion(num_steps=5, distort_limit=0.2 * severity, p=0.3 * severity),\n        ]),\n        \n        'angle': A.Compose([\n            A.ShiftScaleRotate(\n                shift_limit=0.1 * severity,\n                scale_limit=0.2 * severity,\n                rotate_limit=30 * severity,\n                p=0.7 * severity\n            ),\n            A.Perspective(scale=(0.05 * severity, 0.1 * severity), p=0.3 * severity),\n        ]),\n        \n        'shadow': A.Compose([\n            A.RandomShadow(\n                num_shadows_lower=1,\n                num_shadows_upper=int(3 * severity),\n                shadow_dimension=4,\n                shadow_roi=(0, 0.5, 1, 1),\n                p=0.6 * severity\n            ),\n            A.HueSaturationValue(\n                hue_shift_limit=5,\n                sat_shift_limit=20,\n                val_shift_limit=(-30 * severity, 10),\n                p=0.4 * severity\n            ),\n        ]),\n        \n        'partial': A.Compose([\n            A.CoarseDropout(\n                max_holes=int(4 * severity),\n                max_height=int(30 * severity),\n                max_width=int(30 * severity),\n                min_holes=1,\n                p=0.5 * severity\n            ),\n            A.RandomCrop(\n                height=int(256 * (1 - 0.3 * severity)),\n                width=int(256 * (1 - 0.3 * severity)),\n                p=0.3 * severity\n            ),\n        ])\n    }\n    \n    return base_config.get(problem_type, None)\n\ndef adjust_augmentations(config, problem_detection_rates, epoch):\n    print(\"\\nКорректировка аугментаций:\")\n    \n    for problem_type, rate in problem_detection_rates.items():\n        if rate < 70:  # Если детекция ниже 70%\n            # Рассчитываем интенсивность аугментаций на основе текущей производительности\n            severity = min(1.0, (70 - rate) / 70 + 0.3)\n            \n            # Получаем специфичные аугментации для данного типа проблемы\n            aug_config = get_augmentation_config(problem_type, severity)\n            \n            if problem_type == 'blur':\n                config['sharpness'] = min(0.8, config.get('sharpness', 0.4) + 0.1 * severity)\n                print(f\"Увеличена резкость до {config['sharpness']}, severity={severity:.2f}\")\n                \n            elif problem_type in ['dark', 'bright']:\n                config['hsv_v'] = min(0.7, config.get('hsv_v', 0.4) + 0.1 * severity)\n                config['contrast'] = min(0.6, config.get('contrast', 0.3) + 0.1 * severity)\n                print(f\"Усилены параметры яркости/контраста: hsv_v={config['hsv_v']}, contrast={config['contrast']}, severity={severity:.2f}\")\n                \n            elif problem_type == 'angle':\n                config['degrees'] = min(30.0, config.get('degrees', 20.0) + 2.0 * severity)\n                config['perspective'] = min(0.002, config.get('perspective', 0.001) + 0.0002 * severity)\n                print(f\"Усилены угловые преобразования: degrees={config['degrees']}, perspective={config['perspective']}, severity={severity:.2f}\")\n                \n            elif problem_type == 'shadow':\n                config['hsv_v'] = min(0.8, config.get('hsv_v', 0.4) + 0.1 * severity)\n                print(f\"Усилены параметры для теней: hsv_v={config['hsv_v']}, severity={severity:.2f}\")\n                \n            # Добавляем специфичные аугментации в конфигурацию\n            if aug_config:\n                config[f'{problem_type}_augmentations'] = aug_config\n                print(f\"Добавлены специальные аугментации для {problem_type}\")\n    \n    with open(yaml_path, 'w') as f:\n        yaml.dump(config, f, sort_keys=False)\n    \n    return config","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T16:54:41.878297Z","iopub.execute_input":"2025-09-03T16:54:41.878839Z","iopub.status.idle":"2025-09-03T16:54:41.897090Z","shell.execute_reply.started":"2025-09-03T16:54:41.878818Z","shell.execute_reply":"2025-09-03T16:54:41.896470Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Обучение модели с адаптивными аугментациями\nfrom ultralytics import YOLO\n\n# Загружаем модель\nmodel = YOLO(\"/kaggle/input/plate_detection/pytorch/default/1/best.pt\")\n\n# История обучения\nhistory = {\n    'problem_detection_rates': {},\n    'best_rates': {}\n}\n\nfor epoch in range(config['epochs']):\n    print(f\"\\nЭпоха {epoch + 1}/{config['epochs']}\")\n    \n    # Обучение одной эпохи\n    model.train(\n        data=yaml_path,\n        epochs=1,\n        resume=True if epoch > 0 else False,\n        device=0\n    )\n    \n    # Проверяем на сложных случаях\n    problem_detection_rates = validate_on_hard_cases(\n        model, \n        '/kaggle/working/hard_cases_test/images',\n        epoch,\n        problems\n    )\n    \n    # Сохраняем историю\n    history['problem_detection_rates'][epoch] = problem_detection_rates\n    \n    # Обновляем лучшие результаты\n    for problem_type, rate in problem_detection_rates.items():\n        if rate > history['best_rates'].get(problem_type, 0):\n            history['best_rates'][problem_type] = rate\n            print(f\"Новый лучший результат для {problem_type}: {rate:.1f}%\")\n    \n    # Корректируем аугментации каждую эпоху\n    if epoch > 0:  # Начиная со второй эпохи\n        config = adjust_augmentations(config, problem_detection_rates, epoch)\n    \n    # Визуализация прогресса\n    plt.figure(figsize=(12, 6))\n    for problem_type in problems.keys():\n        rates = [history['problem_detection_rates'][e].get(problem_type, 0) \n                for e in range(epoch + 1)]\n        plt.plot(rates, marker='o', label=problem_type)\n    \n    plt.title('Прогресс детекции по типам проблем')\n    plt.xlabel('Эпоха')\n    plt.ylabel('Процент детекций')\n    plt.legend()\n    plt.grid(True)\n    plt.savefig(f'problem_types_progress_epoch_{epoch+1}.png')\n    plt.close()\n\n# Итоговые результаты\nprint(\"\\nИтоговые результаты:\")\nfor problem_type, best_rate in history['best_rates'].items():\n    print(f\"\\n{problem_type}:\")\n    print(f\"  Начальный процент детекций: {history['problem_detection_rates'][0][problem_type]:.1f}%\")\n    print(f\"  Лучший процент детекций: {best_rate:.1f}%\")\n    print(f\"  Конечный процент детекций: {history['problem_detection_rates'][config['epochs']-1][problem_type]:.1f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T16:54:41.897885Z","iopub.execute_input":"2025-09-03T16:54:41.898152Z","iopub.status.idle":"2025-09-03T17:21:35.059984Z","shell.execute_reply.started":"2025-09-03T16:54:41.898127Z","shell.execute_reply":"2025-09-03T17:21:35.058094Z"}},"outputs":[{"name":"stdout","text":"\nЭпоха 1/25\nUltralytics 8.3.192 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/Car_plate_detecting/Config/finetune.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/input/plate_detection/pytorch/default/1/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train6, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/detect/train6, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=True, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\nOverriding class names with single class.\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  2                  -1  1    212864  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 256, 128, 64, 1]        \n  3                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n  4                  -1  1    847616  ultralytics.nn.modules.block.RepNCSPELAN4    [256, 512, 256, 128, 1]       \n  5                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n  6                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n  7                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n  8                  -1  1   2857472  ultralytics.nn.modules.block.RepNCSPELAN4    [512, 512, 512, 256, 1]       \n  9                  -1  1    656896  ultralytics.nn.modules.block.SPPELAN         [512, 512, 256]               \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1    912640  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 256, 256, 128, 1]      \n 16                  -1  1    164352  ultralytics.nn.modules.block.ADown           [256, 256]                    \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1   2988544  ultralytics.nn.modules.block.RepNCSPELAN4    [768, 512, 512, 256, 1]       \n 19                  -1  1    656384  ultralytics.nn.modules.block.ADown           [512, 512]                    \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1   3119616  ultralytics.nn.modules.block.RepNCSPELAN4    [1024, 512, 512, 256, 1]      \n 22        [15, 18, 21]  1   5583571  ultralytics.nn.modules.head.Detect           [1, [256, 512, 512]]          \nYOLOv9c summary: 358 layers, 25,530,003 parameters, 25,529,987 gradients, 103.7 GFLOPs\n\nTransferred 937/937 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2085.3±1017.2 MB/s, size: 187.0 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/finetune_dataset/train/labels.cache... 20505 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 20505/20505 30552114.9it/s 0.0s.0s\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 491.2±167.5 MB/s, size: 277.3 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/finetune_dataset/val/labels.cache... 2563 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 2563/2563 2387827.9it/s 0.0s.0s\nPlotting labels to runs/detect/train6/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 154 weight(decay=0.0), 161 weight(decay=0.0005), 160 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1mruns/detect/train6\u001b[0m\nStarting training for 1 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K        1/1        13G     0.6871     0.3458      0.903         21        640: 100% ━━━━━━━━━━━━ 1282/1282 0.85it/s 25:021.0ss\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 81/81 1.6it/s 49.4s0.7ss\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all       2563       2678      0.976      0.964      0.986      0.822\n\n1 epochs completed in 0.432 hours.\nOptimizer stripped from runs/detect/train6/weights/last.pt, 51.6MB\nOptimizer stripped from runs/detect/train6/weights/best.pt, 51.6MB\n\nValidating runs/detect/train6/weights/best.pt...\nUltralytics 8.3.192 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\nYOLOv9c summary (fused): 156 layers, 25,320,019 parameters, 0 gradients, 102.3 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 81/81 1.8it/s 44.0s0.7ss\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all       2563       2678      0.974      0.965      0.986      0.822\nSpeed: 0.1ms preprocess, 13.3ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1mruns/detect/train6\u001b[0m\n\nПроверка на сложных случаях (эпоха 0):\n\nРезультаты по типам проблем:\nblur: 3/10 (30.0%)\nbright: 1/7 (14.3%)\ndirty: 1/9 (11.1%)\nangle: 2/6 (33.3%)\nshadow: 10/31 (32.3%)\npartial: 1/2 (50.0%)\nНовый лучший результат для blur: 30.0%\nНовый лучший результат для bright: 14.3%\nНовый лучший результат для dirty: 11.1%\nНовый лучший результат для angle: 33.3%\nНовый лучший результат для shadow: 32.3%\nНовый лучший результат для partial: 50.0%\n\nЭпоха 2/25\nUltralytics 8.3.192 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/Car_plate_detecting/config_dataset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.3, dynamic=False, embed=None, epochs=40, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=1e-10, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/kaggle/input/plate_detection/pytorch/default/1/best.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=YOLO9c_CPD_ru10, nbs=64, nms=False, opset=None, optimize=False, optimizer=Adam, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/kaggle/working/logs, rect=False, resume=/kaggle/input/plate_detection/pytorch/default/1/best.pt, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/logs/YOLO9c_CPD_ru10, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=True, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=4, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    622\u001b[0m             }:\n\u001b[0;32m--> 623\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_det_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"yaml_file\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/utils.py\u001b[0m in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\nNote dataset download directory is '{DATASETS_DIR}'. You can update this in '{SETTINGS_FILE}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: Dataset '/kaggle/working/Car_plate_detecting/config_dataset.yaml' images not found, missing path '/kaggle/working/dataset/val'\nNote dataset download directory is '/kaggle/working/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/4258648350.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Обучение одной эпохи\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     model.train(\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myaml_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# manually set model only if not resuming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_model_file_from_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch_distributed_zero_first\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLOCAL_RANK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# avoid auto-downloading dataset multiple times\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"yaml_file\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# for validating 'yolo train data=url.zip' usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memojis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset '{clean_url(self.args.data)}' error ❌ {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Overriding class names with single class.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Dataset '/kaggle/working/Car_plate_detecting/config_dataset.yaml' error ❌ Dataset '/kaggle/working/Car_plate_detecting/config_dataset.yaml' images not found, missing path '/kaggle/working/dataset/val'\nNote dataset download directory is '/kaggle/working/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'"],"ename":"RuntimeError","evalue":"Dataset '/kaggle/working/Car_plate_detecting/config_dataset.yaml' error ❌ Dataset '/kaggle/working/Car_plate_detecting/config_dataset.yaml' images not found, missing path '/kaggle/working/dataset/val'\nNote dataset download directory is '/kaggle/working/datasets'. You can update this in '/root/.config/Ultralytics/settings.json'","output_type":"error"}],"execution_count":32}]}